# word-vectors-comparison

## Methods compared:

- [LDA](#1)
- [LSA](#2)
- [HAL](#3)
- [COALS](#4)
- [GloVe](#5)
- [CBOW](#6)
- [Skip-gram](#6)

## Evaluations:

* Intrinsic evaluations

  word association

  word similarty

  word analogy

* Extrinsic evaluations

  NER
  
## Reference
##### 1 
Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent Dirichlet Allocation. Journal of Machine Learning Research, 3(Jan), 993-1022. 

##### 2
Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. K., & Harshman, R. (1990). Indexing by Latent Semantic Analysis. Journal of the American Society for Information Science, 41(6), 391.   

##### 3
Lund, K., & Burgess, C. (1996). Producing high-dimensional semantic spaces from lexical co-occurrence. Behavior Research Methods, Instruments, & Computers, 28(2), 203-208.   

##### 4
Rohde, D. L., Gonnerman, L. M., & Plaut, D. C. (2006). An improved model of semantic similarity based on lexical co-occurrence. Communications of the ACM, 8, 627-633.   

##### 5
Pennington, J., Socher, R., & Manning, C. (2014). GloVe: Global vectors for word representation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) (pp. 1532-1543). 

##### 6
Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efficient estimation of word representations in vector space. Paper presented at the International Conference on Learning Representations (ICLR) Workshop Track.   
